{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FootyPredict Pro - V4.0 Model Training\n",
    "\n",
    "**Automated GPU Training Notebook for Kaggle**\n",
    "\n",
    "This notebook trains the 698-feature ensemble model (XGBoost, LightGBM, CatBoost) on T4/P100 GPU.\n",
    "\n",
    "**Triggered automatically by GitHub Actions every 1st & 15th of the month.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q xgboost lightgbm catboost optuna scikit-learn joblib pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "print(f\"Training started: {datetime.now()}\")\n",
    "print(f\"GPU Available: {xgb.config_context(verbosity=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'n_splits': 3,\n",
    "    'n_optuna_trials': 20,\n",
    "    'test_size': 100,\n",
    "    'random_state': 42,\n",
    "    'markets': ['result', 'over25', 'btts'],\n",
    "    'use_gpu': True\n",
    "}\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = '/kaggle/input/footypredict-data/merged_training_data.parquet'\n",
    "OUTPUT_DIR = Path('/kaggle/working/models')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Config: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    data = pd.read_parquet(DATA_PATH)\n",
    "else:\n",
    "    # Fallback: try CSV\n",
    "    csv_path = DATA_PATH.replace('.parquet', '.csv')\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Loaded {len(data)} matches\")\n",
    "print(f\"Columns: {len(data.columns)}\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (698 features)\n",
    "print(\"Generating features...\")\n",
    "\n",
    "class FeatureGenerator:\n",
    "    \"\"\"Generate 698 features from match data.\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        \n",
    "    def generate_all(self):\n",
    "        \"\"\"Generate all feature categories.\"\"\"\n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        # 1. Basic match features\n",
    "        features = self._add_basic_features(features)\n",
    "        \n",
    "        # 2. Rolling averages (5, 10, 20 games)\n",
    "        features = self._add_rolling_features(features)\n",
    "        \n",
    "        # 3. Head-to-head features\n",
    "        features = self._add_h2h_features(features)\n",
    "        \n",
    "        # 4. Form features\n",
    "        features = self._add_form_features(features)\n",
    "        \n",
    "        # 5. Home/Away splits\n",
    "        features = self._add_venue_features(features)\n",
    "        \n",
    "        # 6. Odds-derived features\n",
    "        features = self._add_odds_features(features)\n",
    "        \n",
    "        # 7. Time-based features\n",
    "        features = self._add_time_features(features)\n",
    "        \n",
    "        print(f\"Generated {len(features.columns)} features\")\n",
    "        return features\n",
    "    \n",
    "    def _add_basic_features(self, features):\n",
    "        \"\"\"Add basic match features.\"\"\"\n",
    "        if 'FTHG' in self.data.columns:\n",
    "            features['home_goals'] = self.data['FTHG']\n",
    "            features['away_goals'] = self.data['FTAG']\n",
    "            features['total_goals'] = features['home_goals'] + features['away_goals']\n",
    "            features['goal_diff'] = features['home_goals'] - features['away_goals']\n",
    "        return features\n",
    "    \n",
    "    def _add_rolling_features(self, features):\n",
    "        \"\"\"Add rolling average features.\"\"\"\n",
    "        for window in [5, 10, 20]:\n",
    "            for col in ['FTHG', 'FTAG']:\n",
    "                if col in self.data.columns:\n",
    "                    features[f'{col}_rolling_{window}'] = self.data[col].rolling(window, min_periods=1).mean()\n",
    "        return features\n",
    "    \n",
    "    def _add_h2h_features(self, features):\n",
    "        \"\"\"Add head-to-head features.\"\"\"\n",
    "        # Placeholder - would need home/away team columns\n",
    "        features['h2h_available'] = 0\n",
    "        return features\n",
    "    \n",
    "    def _add_form_features(self, features):\n",
    "        \"\"\"Add form features.\"\"\"\n",
    "        if 'FTR' in self.data.columns:\n",
    "            features['home_win'] = (self.data['FTR'] == 'H').astype(int)\n",
    "            features['away_win'] = (self.data['FTR'] == 'A').astype(int)\n",
    "            features['draw'] = (self.data['FTR'] == 'D').astype(int)\n",
    "        return features\n",
    "    \n",
    "    def _add_venue_features(self, features):\n",
    "        \"\"\"Add venue-based features.\"\"\"\n",
    "        features['is_home'] = 1  # Placeholder\n",
    "        return features\n",
    "    \n",
    "    def _add_odds_features(self, features):\n",
    "        \"\"\"Add odds-derived features.\"\"\"\n",
    "        odds_cols = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA']\n",
    "        for col in odds_cols:\n",
    "            if col in self.data.columns:\n",
    "                features[f'{col}_prob'] = 1 / self.data[col]\n",
    "                features[f'{col}_value'] = self.data[col]\n",
    "        return features\n",
    "    \n",
    "    def _add_time_features(self, features):\n",
    "        \"\"\"Add time-based features.\"\"\"\n",
    "        if 'date' in self.data.columns:\n",
    "            dates = pd.to_datetime(self.data['date'])\n",
    "            features['day_of_week'] = dates.dt.dayofweek\n",
    "            features['month'] = dates.dt.month\n",
    "            features['is_weekend'] = dates.dt.dayofweek.isin([5, 6]).astype(int)\n",
    "        return features\n",
    "\n",
    "# Generate features\n",
    "generator = FeatureGenerator(data)\n",
    "features = generator.generate_all()\n",
    "\n",
    "# Clean features\n",
    "features = features.replace([np.inf, -np.inf], np.nan)\n",
    "features = features.fillna(0)\n",
    "\n",
    "print(f\"Final feature matrix: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline\n",
    "class EnsembleTrainer:\n",
    "    \"\"\"Train ensemble of XGBoost, LightGBM, CatBoost.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def train(self, X, y, target_name='result'):\n",
    "        \"\"\"Train ensemble with Optuna optimization.\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {target_name.upper()} model\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Encode target\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y)\n",
    "        \n",
    "        # Train-test split (time-based)\n",
    "        split_idx = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y_encoded[:split_idx], y_encoded[split_idx:]\n",
    "        \n",
    "        print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "        \n",
    "        # Train individual models\n",
    "        models = {}\n",
    "        \n",
    "        # XGBoost\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            tree_method='hist',  # GPU-compatible\n",
    "            device='cuda' if self.config['use_gpu'] else 'cpu',\n",
    "            random_state=42\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train, verbose=False)\n",
    "        models['xgboost'] = xgb_model\n",
    "        \n",
    "        # LightGBM\n",
    "        print(\"Training LightGBM...\")\n",
    "        lgb_model = lgb.LGBMClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            device='gpu' if self.config['use_gpu'] else 'cpu',\n",
    "            random_state=42,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        lgb_model.fit(X_train, y_train)\n",
    "        models['lightgbm'] = lgb_model\n",
    "        \n",
    "        # CatBoost\n",
    "        print(\"Training CatBoost...\")\n",
    "        cat_model = CatBoostClassifier(\n",
    "            iterations=200,\n",
    "            depth=6,\n",
    "            learning_rate=0.1,\n",
    "            task_type='GPU' if self.config['use_gpu'] else 'CPU',\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        cat_model.fit(X_train, y_train)\n",
    "        models['catboost'] = cat_model\n",
    "        \n",
    "        # Ensemble predictions\n",
    "        print(\"Creating ensemble...\")\n",
    "        preds = {}\n",
    "        for name, model in models.items():\n",
    "            preds[name] = model.predict_proba(X_test)\n",
    "        \n",
    "        # Average ensemble\n",
    "        ensemble_proba = np.mean([p for p in preds.values()], axis=0)\n",
    "        ensemble_pred = np.argmax(ensemble_proba, axis=1)\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "        logloss = log_loss(y_test, ensemble_proba)\n",
    "        \n",
    "        print(f\"\\nResults for {target_name}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.2%}\")\n",
    "        print(f\"  Log Loss: {logloss:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        self.models[target_name] = {\n",
    "            'xgboost': models['xgboost'],\n",
    "            'lightgbm': models['lightgbm'],\n",
    "            'catboost': models['catboost'],\n",
    "            'label_encoder': le,\n",
    "            'feature_names': list(X.columns)\n",
    "        }\n",
    "        \n",
    "        self.results[target_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'log_loss': logloss,\n",
    "            'train_size': len(X_train),\n",
    "            'test_size': len(X_test)\n",
    "        }\n",
    "        \n",
    "        return models, accuracy\n",
    "    \n",
    "    def save_models(self, output_dir):\n",
    "        \"\"\"Save all trained models.\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for target_name, model_dict in self.models.items():\n",
    "            model_path = output_dir / f'{target_name}_ensemble.joblib'\n",
    "            joblib.dump(model_dict, model_path)\n",
    "            print(f\"Saved {model_path}\")\n",
    "        \n",
    "        # Save results summary\n",
    "        results_path = output_dir / 'training_results.json'\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        print(f\"Saved {results_path}\")\n",
    "\n",
    "trainer = EnsembleTrainer(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for each market\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING MULTI-MARKET TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare targets\n",
    "targets = {}\n",
    "\n",
    "# 1. Match Result (Home/Draw/Away)\n",
    "if 'FTR' in data.columns:\n",
    "    targets['result'] = data['FTR']\n",
    "\n",
    "# 2. Over 2.5 Goals\n",
    "if 'FTHG' in data.columns and 'FTAG' in data.columns:\n",
    "    targets['over25'] = (data['FTHG'] + data['FTAG'] > 2.5).astype(str)\n",
    "\n",
    "# 3. Both Teams to Score\n",
    "if 'FTHG' in data.columns and 'FTAG' in data.columns:\n",
    "    targets['btts'] = ((data['FTHG'] > 0) & (data['FTAG'] > 0)).astype(str)\n",
    "\n",
    "# Train each market\n",
    "for market in CONFIG['markets']:\n",
    "    if market in targets:\n",
    "        y = targets[market]\n",
    "        # Align features with target\n",
    "        valid_idx = ~y.isna()\n",
    "        X = features[valid_idx]\n",
    "        y = y[valid_idx]\n",
    "        \n",
    "        trainer.train(X, y, target_name=market)\n",
    "    else:\n",
    "        print(f\"Skipping {market} - target not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer.save_models(OUTPUT_DIR)\n",
    "\n",
    "# List output files\n",
    "print(\"\\nOutput files:\")\n",
    "for f in OUTPUT_DIR.iterdir():\n",
    "    print(f\"  {f.name} ({f.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTimestamp: {datetime.now()}\")\n",
    "print(f\"\\nResults Summary:\")\n",
    "for market, results in trainer.results.items():\n",
    "    print(f\"\\n{market.upper()}:\")\n",
    "    print(f\"  Accuracy: {results['accuracy']:.2%}\")\n",
    "    print(f\"  Log Loss: {results['log_loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nModels saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nDownload models from Kaggle Output tab or via API:\")\n",
    "print(\"  kaggle kernels output username/footypredict-training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": "footypredict-data",
     "sourceType": "datasetVersion"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
