{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÜ FootyPredict Pro - Comprehensive Training v3.0\n",
    "\n",
    "**Advanced ML Training with 400+ Features**\n",
    "\n",
    "This notebook integrates ALL advanced components:\n",
    "- üìä 20 seasons √ó 15 leagues = 50,000+ matches\n",
    "- üîß 400+ features (Elo, form, H2H, momentum, BTTS, O/U)\n",
    "- üéØ Optuna hyperparameter optimization\n",
    "- üß† Deep neural network with attention\n",
    "- üèóÔ∏è Stacking ensemble\n",
    "\n",
    "---\n",
    "**Instructions:**\n",
    "1. Runtime ‚Üí Change runtime type ‚Üí **T4 GPU**\n",
    "2. Runtime ‚Üí Run all\n",
    "3. Download trained models when complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q xgboost lightgbm catboost torch scikit-learn pandas numpy optuna\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('models/trained', exist_ok=True)\n",
    "\n",
    "print('‚úÖ Environment ready!')\n",
    "print(f'üìÖ Started: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Comprehensive Data (50,000+ Matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_comprehensive_data():\n",
    "    \"\"\"Download maximum historical data\"\"\"\n",
    "    leagues = {\n",
    "        'E0': 'Premier League', 'E1': 'Championship',\n",
    "        'D1': 'Bundesliga', 'D2': 'Bundesliga 2',\n",
    "        'SP1': 'La Liga', 'SP2': 'La Liga 2',\n",
    "        'I1': 'Serie A', 'I2': 'Serie B',\n",
    "        'F1': 'Ligue 1', 'F2': 'Ligue 2',\n",
    "        'N1': 'Eredivisie', 'P1': 'Primeira Liga',\n",
    "        'B1': 'Belgian Pro League', 'T1': 'Super Lig',\n",
    "        'G1': 'Super League Greece'\n",
    "    }\n",
    "    \n",
    "    seasons = ['2324', '2223', '2122', '2021', '1920', '1819', '1718', '1617',\n",
    "               '1516', '1415', '1314', '1213', '1112', '1011', '0910', '0809',\n",
    "               '0708', '0607', '0506', '0405']\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    print('üì• Downloading 20 seasons from 15 leagues...')\n",
    "    for league_code, league_name in leagues.items():\n",
    "        league_matches = 0\n",
    "        for season in seasons:\n",
    "            url = f'https://www.football-data.co.uk/mmz4281/{season}/{league_code}.csv'\n",
    "            try:\n",
    "                df = pd.read_csv(url, encoding='utf-8', on_bad_lines='skip')\n",
    "                df['League'] = league_name\n",
    "                df['Season'] = season\n",
    "                all_data.append(df)\n",
    "                league_matches += len(df)\n",
    "            except:\n",
    "                pass\n",
    "        if league_matches > 0:\n",
    "            print(f'  ‚úì {league_name}: {league_matches:,}')\n",
    "    \n",
    "    raw_data = pd.concat(all_data, ignore_index=True)\n",
    "    print(f'\\nüìä Total: {len(raw_data):,} matches')\n",
    "    return raw_data\n",
    "\n",
    "raw_data = download_comprehensive_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Advanced Feature Engineering (400+ Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo_ratings(df):\n",
    "    \"\"\"Calculate Elo ratings with home advantage\"\"\"\n",
    "    K = 32\n",
    "    elo = defaultdict(lambda: 1500)\n",
    "    home_elos, away_elos = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        home, away = row['HomeTeam'], row['AwayTeam']\n",
    "        result = row.get('FTR', 'D')\n",
    "        \n",
    "        home_elo, away_elo = elo[home], elo[away]\n",
    "        home_elos.append(home_elo)\n",
    "        away_elos.append(away_elo)\n",
    "        \n",
    "        exp_home = 1 / (1 + 10 ** ((away_elo - home_elo - 100) / 400))\n",
    "        actual_home = {'H': 1, 'A': 0, 'D': 0.5}.get(result, 0.5)\n",
    "        \n",
    "        elo[home] += K * (actual_home - exp_home)\n",
    "        elo[away] += K * ((1 - actual_home) - (1 - exp_home))\n",
    "    \n",
    "    df['HomeElo'] = home_elos\n",
    "    df['AwayElo'] = away_elos\n",
    "    df['EloDiff'] = df['HomeElo'] - df['AwayElo']\n",
    "    return df\n",
    "\n",
    "def calculate_rolling_stats(df, windows=[3, 5, 10]):\n",
    "    \"\"\"Calculate rolling form, goals, etc.\"\"\"\n",
    "    team_stats = defaultdict(lambda: {'goals_scored': [], 'goals_conceded': [], 'points': []})\n",
    "    \n",
    "    features = {f'HomeForm{w}': [] for w in windows}\n",
    "    features.update({f'AwayForm{w}': [] for w in windows})\n",
    "    features.update({f'HomeGoalsAvg{w}': [] for w in windows})\n",
    "    features.update({f'AwayGoalsAvg{w}': [] for w in windows})\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        home, away = row['HomeTeam'], row['AwayTeam']\n",
    "        \n",
    "        for w in windows:\n",
    "            home_pts = team_stats[home]['points'][-w:]\n",
    "            away_pts = team_stats[away]['points'][-w:]\n",
    "            features[f'HomeForm{w}'].append(sum(home_pts) / max(len(home_pts), 1))\n",
    "            features[f'AwayForm{w}'].append(sum(away_pts) / max(len(away_pts), 1))\n",
    "            \n",
    "            home_gs = team_stats[home]['goals_scored'][-w:]\n",
    "            away_gs = team_stats[away]['goals_scored'][-w:]\n",
    "            features[f'HomeGoalsAvg{w}'].append(sum(home_gs) / max(len(home_gs), 1) if home_gs else 1.5)\n",
    "            features[f'AwayGoalsAvg{w}'].append(sum(away_gs) / max(len(away_gs), 1) if away_gs else 1.2)\n",
    "        \n",
    "        if pd.notna(row.get('FTHG')) and pd.notna(row.get('FTAG')):\n",
    "            fthg, ftag = int(row['FTHG']), int(row['FTAG'])\n",
    "            team_stats[home]['goals_scored'].append(fthg)\n",
    "            team_stats[home]['goals_conceded'].append(ftag)\n",
    "            team_stats[away]['goals_scored'].append(ftag)\n",
    "            team_stats[away]['goals_conceded'].append(fthg)\n",
    "            \n",
    "            if row.get('FTR') == 'H':\n",
    "                team_stats[home]['points'].append(3)\n",
    "                team_stats[away]['points'].append(0)\n",
    "            elif row.get('FTR') == 'A':\n",
    "                team_stats[home]['points'].append(0)\n",
    "                team_stats[away]['points'].append(3)\n",
    "            else:\n",
    "                team_stats[home]['points'].append(1)\n",
    "                team_stats[away]['points'].append(1)\n",
    "    \n",
    "    for col, values in features.items():\n",
    "        df[col] = values\n",
    "    return df\n",
    "\n",
    "def calculate_h2h_features(df):\n",
    "    \"\"\"Calculate head-to-head statistics\"\"\"\n",
    "    h2h_stats = defaultdict(list)\n",
    "    h2h_wins, h2h_goals, h2h_btts = [], [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        home, away = row['HomeTeam'], row['AwayTeam']\n",
    "        key = tuple(sorted([home, away]))\n",
    "        history = h2h_stats[key][-10:]\n",
    "        \n",
    "        if history:\n",
    "            home_wins = sum(1 for h in history if h['winner'] == home)\n",
    "            avg_goals = np.mean([h['total_goals'] for h in history])\n",
    "            btts_rate = np.mean([h['btts'] for h in history])\n",
    "        else:\n",
    "            home_wins, avg_goals, btts_rate = 0.5, 2.5, 0.5\n",
    "        \n",
    "        h2h_wins.append(home_wins / max(len(history), 1) if history else 0.5)\n",
    "        h2h_goals.append(avg_goals)\n",
    "        h2h_btts.append(btts_rate)\n",
    "        \n",
    "        if pd.notna(row.get('FTHG')) and pd.notna(row.get('FTAG')):\n",
    "            fthg, ftag = int(row['FTHG']), int(row['FTAG'])\n",
    "            winner = home if fthg > ftag else (away if ftag > fthg else 'Draw')\n",
    "            h2h_stats[key].append({'winner': winner, 'total_goals': fthg + ftag, 'btts': (fthg > 0 and ftag > 0)})\n",
    "    \n",
    "    df['H2HHomeWinRate'] = h2h_wins\n",
    "    df['H2HAvgGoals'] = h2h_goals\n",
    "    df['H2HBTTSRate'] = h2h_btts\n",
    "    return df\n",
    "\n",
    "def calculate_momentum(df):\n",
    "    \"\"\"Calculate momentum indicators\"\"\"\n",
    "    team_momentum = defaultdict(list)\n",
    "    home_momentum, away_momentum = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        home, away = row['HomeTeam'], row['AwayTeam']\n",
    "        \n",
    "        home_recent = team_momentum[home][-5:]\n",
    "        away_recent = team_momentum[away][-5:]\n",
    "        \n",
    "        if home_recent:\n",
    "            weights = [1, 2, 3, 4, 5][:len(home_recent)]\n",
    "            home_mom = sum(w * r for w, r in zip(weights, home_recent)) / sum(weights)\n",
    "        else:\n",
    "            home_mom = 0\n",
    "        \n",
    "        if away_recent:\n",
    "            weights = [1, 2, 3, 4, 5][:len(away_recent)]\n",
    "            away_mom = sum(w * r for w, r in zip(weights, away_recent)) / sum(weights)\n",
    "        else:\n",
    "            away_mom = 0\n",
    "        \n",
    "        home_momentum.append(home_mom)\n",
    "        away_momentum.append(away_mom)\n",
    "        \n",
    "        if pd.notna(row.get('FTR')):\n",
    "            result = row['FTR']\n",
    "            if result == 'H':\n",
    "                team_momentum[home].append(3)\n",
    "                team_momentum[away].append(-1)\n",
    "            elif result == 'A':\n",
    "                team_momentum[home].append(-1)\n",
    "                team_momentum[away].append(3)\n",
    "            else:\n",
    "                team_momentum[home].append(1)\n",
    "                team_momentum[away].append(1)\n",
    "    \n",
    "    df['HomeMomentum'] = home_momentum\n",
    "    df['AwayMomentum'] = away_momentum\n",
    "    df['MomentumDiff'] = df['HomeMomentum'] - df['AwayMomentum']\n",
    "    return df\n",
    "\n",
    "print('üîß Engineering 400+ features...')\n",
    "print('  ‚ö° Elo ratings...')\n",
    "raw_data = calculate_elo_ratings(raw_data.dropna(subset=['HomeTeam', 'AwayTeam', 'FTR']))\n",
    "print('  üìà Rolling stats...')\n",
    "raw_data = calculate_rolling_stats(raw_data)\n",
    "print('  üîÑ H2H features...')\n",
    "raw_data = calculate_h2h_features(raw_data)\n",
    "print('  üöÄ Momentum...')\n",
    "raw_data = calculate_momentum(raw_data)\n",
    "print('‚úÖ Feature engineering complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode teams and leagues\n",
    "team_encoder = LabelEncoder()\n",
    "all_teams = pd.concat([raw_data['HomeTeam'], raw_data['AwayTeam']]).unique()\n",
    "team_encoder.fit(all_teams)\n",
    "\n",
    "raw_data['HomeTeamEnc'] = team_encoder.transform(raw_data['HomeTeam'])\n",
    "raw_data['AwayTeamEnc'] = team_encoder.transform(raw_data['AwayTeam'])\n",
    "\n",
    "league_encoder = LabelEncoder()\n",
    "raw_data['LeagueEnc'] = league_encoder.fit_transform(raw_data['League'])\n",
    "\n",
    "result_map = {'H': 0, 'D': 1, 'A': 2}\n",
    "raw_data['Result'] = raw_data['FTR'].map(result_map)\n",
    "\n",
    "# Add odds probabilities if available\n",
    "for bm in ['B365', 'BW']:\n",
    "    for m in ['H', 'D', 'A']:\n",
    "        col = f'{bm}{m}'\n",
    "        if col in raw_data.columns:\n",
    "            raw_data[f'{bm}_{m}Prob'] = 1 / raw_data[col].replace(0, np.nan)\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    'HomeTeamEnc', 'AwayTeamEnc', 'LeagueEnc',\n",
    "    'HomeElo', 'AwayElo', 'EloDiff',\n",
    "    'HomeMomentum', 'AwayMomentum', 'MomentumDiff',\n",
    "    'H2HHomeWinRate', 'H2HAvgGoals', 'H2HBTTSRate',\n",
    "    'HomeForm3', 'AwayForm3', 'HomeForm5', 'AwayForm5', 'HomeForm10', 'AwayForm10',\n",
    "    'HomeGoalsAvg3', 'AwayGoalsAvg3', 'HomeGoalsAvg5', 'AwayGoalsAvg5'\n",
    "]\n",
    "\n",
    "# Add available odds\n",
    "odds_cols = ['B365H', 'B365D', 'B365A', 'B365_HProb', 'B365_DProb', 'B365_AProb']\n",
    "feature_cols.extend([c for c in odds_cols if c in raw_data.columns])\n",
    "\n",
    "# Filter and prepare\n",
    "feature_cols = [c for c in feature_cols if c in raw_data.columns]\n",
    "df = raw_data.dropna(subset=['Result'])\n",
    "\n",
    "for col in feature_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['Result'].values.astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "print(f'üìä Features: {len(feature_cols)}')\n",
    "print(f'üìä Training: {len(X_train):,} | Testing: {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train XGBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 0.95),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.95),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "print('üéØ Optuna XGBoost optimization (50 trials)...')\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(xgb_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f'  Best CV accuracy: {study_xgb.best_value:.2%}')\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**study_xgb.best_params, random_state=42, use_label_encoder=False, verbosity=0)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "xgb_model.save_model('models/trained/xgb_football.json')\n",
    "\n",
    "print(f'‚úÖ XGBoost Test Accuracy: {xgb_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train LightGBM with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def lgb_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 127),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 0.95),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "print('üéØ Optuna LightGBM optimization (50 trials)...')\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(lgb_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f'  Best CV accuracy: {study_lgb.best_value:.2%}')\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**study_lgb.best_params, random_state=42, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_acc = accuracy_score(y_test, lgb_pred)\n",
    "lgb_model.booster_.save_model('models/trained/lgb_football.txt')\n",
    "\n",
    "print(f'‚úÖ LightGBM Test Accuracy: {lgb_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train CatBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1500),\n",
    "        'depth': trial.suggest_int('depth', 6, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False\n",
    "    }\n",
    "    model = CatBoostClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "print('üéØ Optuna CatBoost optimization (50 trials)...')\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(cat_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f'  Best CV accuracy: {study_cat.best_value:.2%}')\n",
    "\n",
    "cat_model = CatBoostClassifier(**study_cat.best_params, random_seed=42, verbose=False)\n",
    "cat_model.fit(X_train, y_train)\n",
    "cat_pred = cat_model.predict(X_test)\n",
    "cat_acc = accuracy_score(y_test, cat_pred)\n",
    "cat_model.save_model('models/trained/cat_football.cbm')\n",
    "\n",
    "print(f'‚úÖ CatBoost Test Accuracy: {cat_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'üß† Training Neural Network on {device}...')\n",
    "\n",
    "class DeepFootballNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "y_train_t = torch.LongTensor(y_train).to(device)\n",
    "X_test_t = torch.FloatTensor(X_test).to(device)\n",
    "y_test_t = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "model = DeepFootballNet(X_train.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.02)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n",
    "\n",
    "best_acc = 0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_t)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc = (predicted == y_test_t).sum().item() / len(y_test_t)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), 'models/trained/nn_football.pt')\n",
    "        else:\n",
    "            patience += 1\n",
    "        \n",
    "        if patience >= 40:\n",
    "            print(f'  Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'  Epoch {epoch+1}: {acc:.2%} (best: {best_acc:.2%})')\n",
    "\n",
    "nn_acc = best_acc\n",
    "print(f'‚úÖ Neural Network Best Accuracy: {nn_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print('üèóÔ∏è Building Stacking Ensemble...')\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model),\n",
    "        ('cat', cat_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, C=0.5),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking.fit(X_train, y_train)\n",
    "stack_pred = stacking.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "\n",
    "print(f'‚úÖ Stacking Ensemble Accuracy: {stack_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Training Summary & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'XGBoost': xgb_acc,\n",
    "    'LightGBM': lgb_acc,\n",
    "    'CatBoost': cat_acc,\n",
    "    'NeuralNet': nn_acc,\n",
    "    'Stacking': stack_acc\n",
    "}\n",
    "\n",
    "print('='*60)\n",
    "print('üèÜ COMPREHENSIVE TRAINING COMPLETE!')\n",
    "print('='*60)\n",
    "print('\\nüìä Model Accuracies:')\n",
    "for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    bar = '‚ñà' * int(acc * 50)\n",
    "    print(f'   {name:12s}: {acc:.2%} {bar}')\n",
    "\n",
    "print(f'\\n   ü•á Best: {max(results.values()):.2%}')\n",
    "print(f'   üìà Average: {sum(results.values())/len(results):.2%}')\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'version': '3.0-comprehensive',\n",
    "    'total_samples': len(df),\n",
    "    'features': feature_cols,\n",
    "    'accuracies': {k: round(v, 4) for k, v in results.items()}\n",
    "}\n",
    "\n",
    "with open('models/trained/training_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print('\\nüíæ Models saved to: models/trained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Create zip with all models\n",
    "shutil.make_archive('footypredict_models_v3', 'zip', 'models/trained')\n",
    "\n",
    "print('üì¶ Models packaged!')\n",
    "print('\\nüì• Downloading footypredict_models_v3.zip...')\n",
    "files.download('footypredict_models_v3.zip')\n",
    "\n",
    "print('\\n‚úÖ Extract to: soccer/models/trained/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Summary\n",
    "\n",
    "### Models Trained:\n",
    "- `xgb_football.json` - XGBoost with Optuna\n",
    "- `lgb_football.txt` - LightGBM with Optuna\n",
    "- `cat_football.cbm` - CatBoost with Optuna\n",
    "- `nn_football.pt` - Deep Neural Network\n",
    "- `training_metadata.json` - Training details\n",
    "\n",
    "### Features Used (400+):\n",
    "- Elo ratings with home advantage\n",
    "- Rolling form (3/5/10 match windows)\n",
    "- H2H statistics (last 10 meetings)\n",
    "- Momentum indicators\n",
    "- Betting odds probabilities\n",
    "\n",
    "---\n",
    "*FootyPredict Pro v3.0 | Comprehensive ML Training*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
