{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Football Prediction - Google Colab Training\n",
        "\n",
        "**Complete ensemble training pipeline for Google Colab**\n",
        "\n",
        "âœ… Auto-downloads data (no API key needed)\n",
        "âœ… Trains 4 models (XGBoost, LightGBM, CatBoost, Neural Net)\n",
        "âœ… Saves to Google Drive\n",
        "âœ… One-click download\n",
        "\n",
        "**Instructions:**\n",
        "1. Runtime â†’ Change runtime type â†’ GPU (recommended)\n",
        "2. Run all cells\n",
        "3. Download models or save to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Install dependencies\n",
        "!pip install -q xgboost lightgbm catboost torch onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'ðŸ–¥ï¸ Using: {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 1. Download Training Data (No API Key Needed!)"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Download from GitHub (45,000+ international matches)\n",
        "url = 'https://raw.githubusercontent.com/martj42/international_results/master/results.csv'\n",
        "df = pd.read_csv(url)\n",
        "print(f'âœ… Loaded {len(df):,} matches from 1872-2024')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 2. Feature Engineering"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FeatureEngineer:\n",
        "    def __init__(self, K=32):\n",
        "        self.elo = {}\n",
        "        self.K = K\n",
        "        self.team_encoder = LabelEncoder()\n",
        "    \n",
        "    def get_elo(self, team):\n",
        "        return self.elo.get(team, 1500)\n",
        "    \n",
        "    def update_elo(self, home, away, result):\n",
        "        h_elo, a_elo = self.get_elo(home), self.get_elo(away)\n",
        "        exp_h = 1 / (1 + 10**((a_elo - h_elo) / 400))\n",
        "        if result == 'H': s_h, s_a = 1, 0\n",
        "        elif result == 'A': s_h, s_a = 0, 1\n",
        "        else: s_h, s_a = 0.5, 0.5\n",
        "        self.elo[home] = h_elo + self.K * (s_h - exp_h)\n",
        "        self.elo[away] = a_elo + self.K * (s_a - (1 - exp_h))\n",
        "    \n",
        "    def process(self, df):\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.sort_values('date').reset_index(drop=True)\n",
        "        \n",
        "        # Result column\n",
        "        df['result'] = np.where(df['home_score'] > df['away_score'], 'H',\n",
        "                                np.where(df['home_score'] < df['away_score'], 'A', 'D'))\n",
        "        \n",
        "        # Calculate Elo for each match\n",
        "        print('ðŸ“Š Calculating Elo ratings...')\n",
        "        elo_h, elo_a, elo_diff = [], [], []\n",
        "        for _, row in df.iterrows():\n",
        "            h, a = self.get_elo(row['home_team']), self.get_elo(row['away_team'])\n",
        "            elo_h.append(h); elo_a.append(a); elo_diff.append(h - a)\n",
        "            self.update_elo(row['home_team'], row['away_team'], row['result'])\n",
        "        \n",
        "        df['home_elo'] = elo_h\n",
        "        df['away_elo'] = elo_a\n",
        "        df['elo_diff'] = elo_diff\n",
        "        \n",
        "        # Encode teams\n",
        "        all_teams = pd.concat([df['home_team'], df['away_team']]).unique()\n",
        "        self.team_encoder.fit(all_teams)\n",
        "        df['home_enc'] = self.team_encoder.transform(df['home_team'])\n",
        "        df['away_enc'] = self.team_encoder.transform(df['away_team'])\n",
        "        \n",
        "        # Date features\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['dow'] = df['date'].dt.dayofweek\n",
        "        \n",
        "        print(f'âœ… Processed {len(df):,} matches with {len(self.elo):,} teams')\n",
        "        return df\n",
        "\n",
        "fe = FeatureEngineer()\n",
        "df = fe.process(df)\n",
        "\n",
        "# Show top teams by Elo\n",
        "top_teams = sorted(fe.elo.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "print('\\nðŸ† Top 10 Teams by Elo:')\n",
        "for i, (team, elo) in enumerate(top_teams, 1):\n",
        "    print(f'  {i}. {team}: {elo:.0f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 3. Prepare Training Data"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Features and target\n",
        "FEATURES = ['home_enc', 'away_enc', 'home_elo', 'away_elo', 'elo_diff', 'year', 'month', 'dow']\n",
        "\n",
        "le_result = LabelEncoder()\n",
        "df['result_enc'] = le_result.fit_transform(df['result'])\n",
        "\n",
        "X = df[FEATURES].values\n",
        "y = df['result_enc'].values\n",
        "\n",
        "# Time-based split (train on past, test on recent)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "print(f'ðŸ“Š Training set: {len(X_train):,} matches')\n",
        "print(f'ðŸ“Š Test set: {len(X_test):,} matches')\n",
        "print(f'ðŸ“Š Classes: {list(le_result.classes_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 4. Train Ensemble Models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "models = {}\n",
        "\n",
        "print('ðŸš€ Training XGBoost...')\n",
        "xgb = XGBClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, \n",
        "                    random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "models['xgb'] = xgb\n",
        "xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
        "print(f'   âœ… XGBoost Accuracy: {xgb_acc:.4f}')\n",
        "\n",
        "print('ðŸš€ Training LightGBM...')\n",
        "lgb = LGBMClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=42, verbose=-1)\n",
        "lgb.fit(X_train, y_train)\n",
        "models['lgb'] = lgb\n",
        "lgb_acc = accuracy_score(y_test, lgb.predict(X_test))\n",
        "print(f'   âœ… LightGBM Accuracy: {lgb_acc:.4f}')\n",
        "\n",
        "print('ðŸš€ Training CatBoost...')\n",
        "cat = CatBoostClassifier(iterations=300, depth=8, learning_rate=0.05, random_state=42, verbose=0)\n",
        "cat.fit(X_train, y_train)\n",
        "models['cat'] = cat\n",
        "cat_acc = accuracy_score(y_test, cat.predict(X_test))\n",
        "print(f'   âœ… CatBoost Accuracy: {cat_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 5. Train Neural Network"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FootballNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden),\n",
        "            nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(hidden, 64),\n",
        "            nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# Train\n",
        "print('ðŸš€ Training Neural Network...')\n",
        "net = FootballNet(len(FEATURES)).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "X_t = torch.FloatTensor(X_train_s).to(DEVICE)\n",
        "y_t = torch.LongTensor(y_train).to(DEVICE)\n",
        "\n",
        "for epoch in range(100):\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(net(X_t), y_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 25 == 0:\n",
        "        print(f'   Epoch {epoch+1}/100, Loss: {loss.item():.4f}')\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    nn_preds = net(torch.FloatTensor(X_test_s).to(DEVICE)).argmax(1).cpu().numpy()\n",
        "nn_acc = accuracy_score(y_test, nn_preds)\n",
        "print(f'   âœ… Neural Net Accuracy: {nn_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 6. Ensemble Prediction"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "WEIGHTS = {'xgb': 0.30, 'lgb': 0.30, 'cat': 0.25, 'nn': 0.15}\n",
        "\n",
        "def ensemble_predict(X, X_scaled, models, net, weights=WEIGHTS):\n",
        "    probs = np.zeros((len(X), 3))\n",
        "    probs += weights['xgb'] * models['xgb'].predict_proba(X)\n",
        "    probs += weights['lgb'] * models['lgb'].predict_proba(X)\n",
        "    probs += weights['cat'] * models['cat'].predict_proba(X)\n",
        "    \n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        nn_probs = torch.softmax(net(torch.FloatTensor(X_scaled).to(DEVICE)), dim=1).cpu().numpy()\n",
        "    probs += weights['nn'] * nn_probs\n",
        "    return probs\n",
        "\n",
        "ens_probs = ensemble_predict(X_test, X_test_s, models, net)\n",
        "ens_preds = ens_probs.argmax(1)\n",
        "ens_acc = accuracy_score(y_test, ens_preds)\n",
        "\n",
        "print('\\nðŸ† FINAL RESULTS:')\n",
        "print(f'   XGBoost:    {xgb_acc:.4f}')\n",
        "print(f'   LightGBM:   {lgb_acc:.4f}')\n",
        "print(f'   CatBoost:   {cat_acc:.4f}')\n",
        "print(f'   Neural Net: {nn_acc:.4f}')\n",
        "print(f'   â­ ENSEMBLE: {ens_acc:.4f}')\n",
        "\n",
        "print('\\nðŸ“Š Classification Report:')\n",
        "print(classification_report(y_test, ens_preds, target_names=le_result.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 7. Export Models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('trained_models', exist_ok=True)\n",
        "\n",
        "# Save models\n",
        "models['xgb'].save_model('trained_models/xgb_football.json')\n",
        "models['lgb'].booster_.save_model('trained_models/lgb_football.txt')\n",
        "models['cat'].save_model('trained_models/cat_football.cbm')\n",
        "torch.save(net.state_dict(), 'trained_models/nn_football.pt')\n",
        "\n",
        "# Save encoders and config\n",
        "with open('trained_models/encoders.pkl', 'wb') as f:\n",
        "    pickle.dump({'team_enc': fe.team_encoder, 'result_enc': le_result, 'scaler': scaler}, f)\n",
        "\n",
        "with open('trained_models/elo_ratings.json', 'w') as f:\n",
        "    json.dump(fe.elo, f)\n",
        "\n",
        "with open('trained_models/model_meta.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'features': FEATURES,\n",
        "        'classes': list(le_result.classes_),\n",
        "        'ensemble_weights': WEIGHTS,\n",
        "        'accuracy': float(ens_acc),\n",
        "        'num_teams': len(fe.elo)\n",
        "    }, f, indent=2)\n",
        "\n",
        "print('âœ… All models saved to trained_models/')\n",
        "!ls -la trained_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 8. Download Models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create ZIP file for easy download\n",
        "!cd trained_models && zip -r ../football_models.zip .\n",
        "\n",
        "from google.colab import files\n",
        "files.download('football_models.zip')\n",
        "\n",
        "print('\\nðŸ“¥ Download complete! Extract to your Flask app:')\n",
        "print('   - xgb_football.json â†’ models/trained/')\n",
        "print('   - lgb_football.txt â†’ models/trained/')\n",
        "print('   - cat_football.cbm â†’ models/trained/')\n",
        "print('   - nn_football.pt â†’ models/trained/')\n",
        "print('   - encoders.pkl â†’ models/config/')\n",
        "print('   - elo_ratings.json â†’ models/config/')\n",
        "print('   - model_meta.json â†’ models/config/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 9. (Optional) Save to Google Drive"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Uncomment to save to Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r trained_models /content/drive/MyDrive/football_models\n",
        "# print('âœ… Saved to Google Drive!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 10. Test Prediction"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def predict_match(home_team, away_team):\n",
        "    # Get Elo\n",
        "    h_elo = fe.elo.get(home_team, 1500)\n",
        "    a_elo = fe.elo.get(away_team, 1500)\n",
        "    \n",
        "    # Encode teams\n",
        "    try:\n",
        "        h_enc = fe.team_encoder.transform([home_team])[0]\n",
        "        a_enc = fe.team_encoder.transform([away_team])[0]\n",
        "    except:\n",
        "        h_enc, a_enc = 0, 0\n",
        "    \n",
        "    # Features\n",
        "    import datetime\n",
        "    now = datetime.datetime.now()\n",
        "    features = np.array([[h_enc, a_enc, h_elo, a_elo, h_elo-a_elo, now.year, now.month, now.weekday()]])\n",
        "    \n",
        "    # Ensemble prediction\n",
        "    probs = ensemble_predict(features, scaler.transform(features), models, net)\n",
        "    \n",
        "    # Results\n",
        "    classes = le_result.classes_\n",
        "    pred_idx = probs[0].argmax()\n",
        "    \n",
        "    print(f'\\nâš½ {home_team} vs {away_team}')\n",
        "    print(f'   Elo: {h_elo:.0f} vs {a_elo:.0f}')\n",
        "    print(f'   Home Win: {probs[0][list(classes).index(\"H\")]*100:.1f}%')\n",
        "    print(f'   Draw: {probs[0][list(classes).index(\"D\")]*100:.1f}%')\n",
        "    print(f'   Away Win: {probs[0][list(classes).index(\"A\")]*100:.1f}%')\n",
        "    print(f'   ðŸ† Prediction: {\"Home Win\" if classes[pred_idx]==\"H\" else \"Away Win\" if classes[pred_idx]==\"A\" else \"Draw\"}')\n",
        "\n",
        "# Test predictions\n",
        "predict_match('Germany', 'Brazil')\n",
        "predict_match('Argentina', 'France')\n",
        "predict_match('England', 'Spain')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {"provenance": []},
    "kernelspec": {"display_name": "Python 3", "name": "python3"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
