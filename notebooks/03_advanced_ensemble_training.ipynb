{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Advanced Football Prediction - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a complete training pipeline:\n",
        "1. Load pre-trained models from HuggingFace\n",
        "2. Download and prepare training data\n",
        "3. Fine-tune models on football data\n",
        "4. Export for production use\n",
        "\n",
        "**Run on Kaggle with GPU enabled for best performance!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "!pip install -q torch transformers huggingface_hub xgboost lightgbm catboost\n",
        "!pip install -q onnx onnxruntime kagglehub pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, brier_score_loss\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 1. Load Training Data from Multiple Sources"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def load_kaggle_datasets():\n",
        "    dfs = []\n",
        "    # Try multiple dataset sources\n",
        "    sources = [\n",
        "        '/kaggle/input/international-football-results-from-1872-to-2017/results.csv',\n",
        "        '/kaggle/input/football-events/events.csv',\n",
        "    ]\n",
        "    for src in sources:\n",
        "        try:\n",
        "            df = pd.read_csv(src)\n",
        "            dfs.append(df)\n",
        "            print(f'Loaded {len(df)} rows from {src}')\n",
        "        except: pass\n",
        "    \n",
        "    if not dfs:\n",
        "        # Generate sample data\n",
        "        print('Creating sample training data...')\n",
        "        np.random.seed(42)\n",
        "        n = 10000\n",
        "        df = pd.DataFrame({\n",
        "            'date': pd.date_range('2015-01-01', periods=n, freq='D'),\n",
        "            'home_team': np.random.choice(['Team'+str(i) for i in range(50)], n),\n",
        "            'away_team': np.random.choice(['Team'+str(i) for i in range(50)], n),\n",
        "            'home_score': np.random.randint(0, 5, n),\n",
        "            'away_score': np.random.randint(0, 5, n)\n",
        "        })\n",
        "        dfs.append(df)\n",
        "    \n",
        "    return pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0]\n",
        "\n",
        "df = load_kaggle_datasets()\n",
        "print(f'Total samples: {len(df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 2. Feature Engineering"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FeatureEngineer:\n",
        "    def __init__(self):\n",
        "        self.elo = {}\n",
        "        self.team_encoder = LabelEncoder()\n",
        "        self.scaler = StandardScaler()\n",
        "        self.K = 32\n",
        "    \n",
        "    def get_elo(self, team):\n",
        "        return self.elo.get(team, 1500)\n",
        "    \n",
        "    def update_elo(self, home, away, result):\n",
        "        h_elo, a_elo = self.get_elo(home), self.get_elo(away)\n",
        "        exp_h = 1 / (1 + 10**((a_elo - h_elo) / 400))\n",
        "        \n",
        "        if result == 'H': s_h, s_a = 1, 0\n",
        "        elif result == 'A': s_h, s_a = 0, 1\n",
        "        else: s_h, s_a = 0.5, 0.5\n",
        "        \n",
        "        self.elo[home] = h_elo + self.K * (s_h - exp_h)\n",
        "        self.elo[away] = a_elo + self.K * (s_a - (1 - exp_h))\n",
        "    \n",
        "    def process(self, df):\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.sort_values('date')\n",
        "        \n",
        "        # Result\n",
        "        df['result'] = np.where(df['home_score'] > df['away_score'], 'H',\n",
        "                       np.where(df['home_score'] < df['away_score'], 'A', 'D'))\n",
        "        \n",
        "        # Elo ratings\n",
        "        elo_h, elo_a, elo_diff = [], [], []\n",
        "        for _, row in df.iterrows():\n",
        "            h, a = self.get_elo(row['home_team']), self.get_elo(row['away_team'])\n",
        "            elo_h.append(h); elo_a.append(a); elo_diff.append(h - a)\n",
        "            self.update_elo(row['home_team'], row['away_team'], row['result'])\n",
        "        \n",
        "        df['home_elo'], df['away_elo'], df['elo_diff'] = elo_h, elo_a, elo_diff\n",
        "        \n",
        "        # Team encoding\n",
        "        all_teams = pd.concat([df['home_team'], df['away_team']]).unique()\n",
        "        self.team_encoder.fit(all_teams)\n",
        "        df['home_enc'] = self.team_encoder.transform(df['home_team'])\n",
        "        df['away_enc'] = self.team_encoder.transform(df['away_team'])\n",
        "        \n",
        "        # Date features\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['dow'] = df['date'].dt.dayofweek\n",
        "        \n",
        "        return df\n",
        "\n",
        "fe = FeatureEngineer()\n",
        "df = fe.process(df)\n",
        "print(df[['home_team', 'away_team', 'home_elo', 'away_elo', 'result']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 3. Prepare Training Data"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "FEATURES = ['home_enc', 'away_enc', 'home_elo', 'away_elo', 'elo_diff', 'year', 'month', 'dow']\n",
        "TARGET = 'result'\n",
        "\n",
        "le_result = LabelEncoder()\n",
        "df['result_enc'] = le_result.fit_transform(df['result'])\n",
        "\n",
        "X = df[FEATURES].values\n",
        "y = df['result_enc'].values\n",
        "\n",
        "# Time-based split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "print(f'Train: {len(X_train)}, Test: {len(X_test)}')\n",
        "print(f'Classes: {le_result.classes_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 4. Train Ensemble Models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "models = {}\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "models['xgb'] = xgb\n",
        "print(f'XGBoost Accuracy: {accuracy_score(y_test, xgb.predict(X_test)):.4f}')\n",
        "\n",
        "# LightGBM\n",
        "lgb = LGBMClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=42, verbose=-1)\n",
        "lgb.fit(X_train, y_train)\n",
        "models['lgb'] = lgb\n",
        "print(f'LightGBM Accuracy: {accuracy_score(y_test, lgb.predict(X_test)):.4f}')\n",
        "\n",
        "# CatBoost\n",
        "cat = CatBoostClassifier(iterations=300, depth=8, learning_rate=0.05, random_state=42, verbose=0)\n",
        "cat.fit(X_train, y_train)\n",
        "models['cat'] = cat\n",
        "print(f'CatBoost Accuracy: {accuracy_score(y_test, cat.predict(X_test)):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 5. Neural Network Model"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class FootballNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden),\n",
        "            nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(hidden, 64),\n",
        "            nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Normalize\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# Train\n",
        "net = FootballNet(len(FEATURES)).to(DEVICE)\n",
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "X_t = torch.FloatTensor(X_train_s).to(DEVICE)\n",
        "y_t = torch.LongTensor(y_train).to(DEVICE)\n",
        "\n",
        "for epoch in range(100):\n",
        "    net.train()\n",
        "    opt.zero_grad()\n",
        "    loss = loss_fn(net(X_t), y_t)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    preds = net(torch.FloatTensor(X_test_s).to(DEVICE)).argmax(1).cpu().numpy()\n",
        "print(f'Neural Net Accuracy: {accuracy_score(y_test, preds):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 6. Ensemble Prediction"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def ensemble_predict(X, models, net, scaler, weights={'xgb':0.3, 'lgb':0.3, 'cat':0.25, 'nn':0.15}):\n",
        "    probs = np.zeros((len(X), 3))\n",
        "    \n",
        "    probs += weights['xgb'] * models['xgb'].predict_proba(X)\n",
        "    probs += weights['lgb'] * models['lgb'].predict_proba(X)\n",
        "    probs += weights['cat'] * models['cat'].predict_proba(X)\n",
        "    \n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        nn_probs = torch.softmax(net(torch.FloatTensor(scaler.transform(X)).to(DEVICE)), dim=1).cpu().numpy()\n",
        "    probs += weights['nn'] * nn_probs\n",
        "    \n",
        "    return probs / sum(weights.values())\n",
        "\n",
        "ens_probs = ensemble_predict(X_test, models, net, scaler)\n",
        "ens_preds = ens_probs.argmax(1)\n",
        "print(f'Ensemble Accuracy: {accuracy_score(y_test, ens_preds):.4f}')\n",
        "print(classification_report(y_test, ens_preds, target_names=le_result.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## 7. Export Models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pickle, json\n",
        "\n",
        "# Save XGBoost\n",
        "models['xgb'].save_model('xgb_football.json')\n",
        "\n",
        "# Save LightGBM\n",
        "models['lgb'].booster_.save_model('lgb_football.txt')\n",
        "\n",
        "# Save CatBoost\n",
        "models['cat'].save_model('cat_football.cbm')\n",
        "\n",
        "# Save Neural Net\n",
        "torch.save(net.state_dict(), 'nn_football.pt')\n",
        "\n",
        "# Save encoders and scaler\n",
        "with open('encoders.pkl', 'wb') as f:\n",
        "    pickle.dump({'team_enc': fe.team_encoder, 'result_enc': le_result, 'scaler': scaler}, f)\n",
        "\n",
        "# Save Elo ratings\n",
        "with open('elo_ratings.json', 'w') as f:\n",
        "    json.dump(fe.elo, f)\n",
        "\n",
        "# Metadata\n",
        "meta = {\n",
        "    'features': FEATURES,\n",
        "    'classes': list(le_result.classes_),\n",
        "    'ensemble_weights': {'xgb':0.3, 'lgb':0.3, 'cat':0.25, 'nn':0.15},\n",
        "    'accuracy': float(accuracy_score(y_test, ens_preds))\n",
        "}\n",
        "with open('model_meta.json', 'w') as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print('All models exported!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¥ Download Files\n",
        "\n",
        "After running, download these files for your Flask app:\n",
        "```\n",
        "xgb_football.json   â†’ models/trained/\n",
        "lgb_football.txt    â†’ models/trained/\n",
        "cat_football.cbm    â†’ models/trained/\n",
        "nn_football.pt      â†’ models/trained/\n",
        "encoders.pkl        â†’ models/config/\n",
        "elo_ratings.json    â†’ models/config/\n",
        "model_meta.json     â†’ models/config/\n",
        "```"
      ]
    }
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
  "nbformat": 4,
  "nbformat_minor": 4
}
